{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Mining Frequent Patterns, Associations & Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Pattern Analysis\n",
    "\n",
    "- **Frequent patterns** in a data set\n",
    "    - *a set of items*\n",
    "    - *subsequences*\n",
    "    - *substructures*\n",
    "- Examples\n",
    "    - Web log\n",
    "    - Road traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "\n",
    "- **Frequent itemset**\n",
    "    - $X = \\{x_1, x_2, \\ldots, x_k\\}$\n",
    "- **Association rule** $X \\Rightarrow Y$\n",
    "    - **support**: probability that a transaction contains $X \\cup Y$\n",
    "    - **confidence**: conditional probability that a transaction containing $X$ also contains $Y$\n",
    "    - **minimum support, minimum confidence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "|Tid|Items|\n",
    "|---|---|\n",
    "|1|A,B,D|\n",
    "|2|A,C,D|\n",
    "|3|A,D,E|\n",
    "|4|B,E,F|\n",
    "|5|B,C,D,E,F|\n",
    "\n",
    "- Let min_sup = 50%, min_conf = 50%\n",
    "- Frequent patterns\n",
    "    - A **3**, B **3**, D **4**, E **3**, AD **3**\n",
    "- Association rules\n",
    "    - A $\\Rightarrow$ D (**60**%, **100**%)\n",
    "    - D $\\Rightarrow$ A (**60**%, **75**%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining Association Rules\n",
    "\n",
    "- Two-step process\n",
    "    - find all **frequent itemsets** (w/ min_sup)\n",
    "    - generate **strong association rules** from the frequent itemsets (min_sup, min_conf)\n",
    "- A long pattern contains a combinatorial **number of subpatterns** (e.g., 100 items)\n",
    "    - $\\displaystyle {100 \\choose 1} + {100 \\choose 2} + \\cdots + {100 \\choose 100} = 2^{100} - 1 \\approx 1.27 \\times 10^{30}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed & Max Patterns\n",
    "\n",
    "- Solution: mine closed patterns & max-patterns\n",
    "- **Closed pattern** $X$\n",
    "    - no super-pattern $Y \\supset X$ w/ the same support\n",
    "- **Max-pattern** $X$\n",
    "    - no super-pattern $Y \\supset X$\n",
    "- Closed pattern is a lossless compression of frequent patterns\n",
    "    - reducing the number of patterns and rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "- $\\{<a_1,\\ldots,a_{100}>,<a_1,\\ldots,a_{50}>\\}$, min_sup = 0.5\n",
    "- Frequent pattern?\n",
    "    - all item combinations\n",
    "- Closed pattern?\n",
    "    - $<a_1,\\ldots,a_{100}>$: 1\n",
    "    - $<a_1,\\ldots,a_{50}>$: 2\n",
    "- Max-pattern?\n",
    "    - $<a_1,\\ldots,a_{100}>$: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori Algorithm\n",
    "\n",
    "- **Apriori property**\n",
    "    - subset of a freq. itemset is also frequent\n",
    "    - e.g., {beer, diaper, nuts}, {beer, diaper}\n",
    "- **Apriori pruning**\n",
    "    - if X is infrequent,\n",
    "    - then superset of X is pruned\n",
    "- Procedure\n",
    "    1. scan DB to get freq. **1-itemset**\n",
    "    1. generate candidate (k+1)-itemsets from freq. **k-itemsets**\n",
    "    1. test candidate **(k+1)-itemsets** against DB\n",
    "    1. stop when no freq. or candidate itemsets can be generated\n",
    "\n",
    "![Apriori Algorithm Example](./img/6.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Details\n",
    "\n",
    "- **Self-joining** of k-itemsets to generate (k+1)-itemsets\n",
    "    - two k-itemsets are joined if their first (k-1) items are the same\n",
    "- **Pruning**: remove if subset not frequent\n",
    "- Example: L3 = {abc, abd, acd, ace, bcd}\n",
    "    - abc and abd $\\Rightarrow$ abcd\n",
    "    - acd and ace $\\Rightarrow$ acde\n",
    "    - acde pruned because ade is not in L3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interestingness Measure\n",
    "\n",
    "- Association rule\n",
    "    - A $\\Rightarrow$ B [support, confidence]\n",
    "- A strong association rule\n",
    "    - play basketball $\\Rightarrow$ eat cereal [40%, 66.7%]\n",
    "- The rule is misleading\n",
    "    - overall, 75% of students eat cereal\n",
    "    - play basketball $\\Rightarrow$ not eat cereal [20%, 33.3%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Rules\n",
    "\n",
    "- Correlation rule\n",
    "    - A $\\Rightarrow$ B [support, confidence, **correlation**]\n",
    "- Measure of dependent/correlated events\n",
    "    - $\\displaystyle lift(A, b) = \\frac{P(A \\cup B)}{P(A)P(B)}$\n",
    "- lift = 1? $\\quad$ **independent**\n",
    "- lift < 1? $\\quad$ **negatively dependent**\n",
    "- lift > 1? $\\quad$ **positively dependent**\n",
    "\n",
    "![Correlation Rules](./img/6.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Pattern Mining\n",
    "\n",
    "- Challenges\n",
    "    - multiple **scans** of the whole data set\n",
    "    - a huge number of **candidates**\n",
    "    - tedious **support counting** for candidates\n",
    "- Improving Apriori: general ideas\n",
    "    - reduce data scans\n",
    "    - reduce number of candidates\n",
    "    - facilitate support counting of candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition: Two Data Scans\n",
    "\n",
    "- A frequent itemset must be frequent in at least one partition\n",
    "- Partition size? # of partitions?\n",
    "    - each partition fits into main memory\n",
    "\n",
    "![Partition Two Data Scans](./img/6.3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling for Freq. Patterns\n",
    "\n",
    "- Select a sample data set\n",
    "- Mine frequent patterns within sample\n",
    "    - may use a lower min_sup\n",
    "- Scan whole data set for actual support\n",
    "    - only check closed patterns\n",
    "    - e.g., check **abcd** instead of **ab**, **acd**, ..., etc.\n",
    "- Scan again to find missed frequent patterns\n",
    "- Sample size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Reduction\n",
    "\n",
    "- If a transaction T does not contain any frequent k-itemset\n",
    "    - then for any h > k, no need to check T when searching for frequent h-itemset\n",
    "- Implementation\n",
    "    - sequential scan\n",
    "    - vs. random access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce #Candidates\n",
    "\n",
    "- Hash itemsets to buckets\n",
    "- If a hash bucket count is below support threshold\n",
    "    - them itemsets in that hash bucket are not frequent itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Itemset Counting\n",
    "\n",
    "- If A & D are freq., start count for AD\n",
    "- If BC, BD, CD are freq., start count for BCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Support of Candidates\n",
    "\n",
    "- Why counting candidate support a problem?\n",
    "    - #candidates: total, per transaction\n",
    "- Method\n",
    "    - store candidate itemsets in a **hash-tree**\n",
    "    - **leaf-node** contains a list of itemsets and counts\n",
    "    - **interior node** contains a hash table\n",
    "    - **subset function**: finds all candidates contained in a transaction\n",
    "\n",
    "![Count Support of Candidates](./img/6.4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical Data Format\n",
    "\n",
    "- **Horizontal** data format\n",
    "    - T1: {A, D, E, F}\n",
    "- **Vertical** data format\n",
    "    - t(AD) = {T1, T6, ...}\n",
    "- Derive closed pattern via **vertical intersection**\n",
    "    - t(X) = {T1, T2, T3} and t(Y) = {T1, T3, T4}\n",
    "    - t(XY) = {T1, T3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Itemset Mining\n",
    "\n",
    "- Multiple **data scans** are costly\n",
    "- Mining **long patterns** needs many scans and generates lots of candidates\n",
    "    - e.g., 100 itemsets: #scans, $candidates\n",
    "- **Bottleneck**: candidate generation & test\n",
    "- Can we avoid candidate generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP-growth\n",
    "\n",
    "- Find frequent itemsets without candidate generation\n",
    "- Grow long patterns from short ones using local frequent items\n",
    "- Example\n",
    "    - **abc** is a frequent itemset; get all transacitons with abc: **DB | abc**\n",
    "    - **d** is a local frequent item in DB | abc\n",
    "    - then **abcd** is a frequent itemset\n",
    "- Idea: Frequent pattern growth\n",
    "    - recursively grow freq. patterns by pattern and data partition\n",
    "- Method\n",
    "    - freq. item $\\Rightarrow$ conditional pattern base $\\Rightarrow$ conditional FP-tree\n",
    "    - repeat on each newly created FP-tree\n",
    "    - until FP-tree is empty or single path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP-tree Construction\n",
    "\n",
    "- Scan, find freq. 1-itemset\n",
    "- Sort freq. items in descending frequency\n",
    "- Scan, construct FP-tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Pattern Base\n",
    "\n",
    "- Traverse links of each frequent item, prefix paths\n",
    "\n",
    "![Conditional Pattern Base](./img/6.5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional FP-trees\n",
    "\n",
    "![Conditional FP trees](./img/6.6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP-growth vs. Apriori\n",
    "\n",
    "![FP growth vs Apriori](./img/6.7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Correlation Measures\n",
    "\n",
    "$\\displaystyle all\\_conf(A,B) = \\frac{\\sup(A \\cup B)}{\\max\\{\\sup(A),\\sup(B)\\}} = \\min\\{P(A|B),P(B|A)\\}$\n",
    "\n",
    "$max\\_conf(A,B) = \\max\\{P(A|B),P(B|A)\\}$\n",
    "\n",
    "$\\displaystyle Kulc(A,B) = \\frac{1}{2}(P(A|B) + P(B|A))$\n",
    "\n",
    "$\\displaystyle cosine(A,B) = \\frac{P(A \\cup B)}{\\sqrt{P(A) \\times P(B)}} = \\frac{\\sup(A \\cup B)}{\\sqrt{\\sup(A) \\times \\sup(B)}} = \\sqrt{P(A|B) \\times P(B|A)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "![Correlation measures comparison](./img/6.8.png)\n",
    "\n",
    "- **Null-transaction**: e.g., $\\neg m, \\neg c$\n",
    "- **Null-variant**: lift and $X^2$\n",
    "- **Null-invariant**: all_conf, max_conf, Kulc, cosine\n",
    "- **Imbalance ratio**\n",
    "    - $\\displaystyle IR(A,B) = \\frac{|\\sup(A) - \\sup(B)|}{\\sup(A) + \\sup(B) - \\sup(A \\cup B)}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
